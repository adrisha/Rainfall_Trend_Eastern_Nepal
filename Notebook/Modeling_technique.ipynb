{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a3df807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b52e737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature-engineered data loaded successfully.\n",
      "\n",
      "--- Regression Task (Predicting rainfall_sum) ---\n",
      "Data split: Training (172403 rows), Validation (43101 rows)\n",
      "\n",
      "Training LinearRegression...\n",
      "LinearRegression Metrics: {'MAE': 0.16553317330954534, 'RMSE': 0.3631788987097078, 'R2': 0.8600617647783155}\n",
      "\n",
      "Training RandomForestRegressor...\n",
      "RandomForestRegressor Metrics: {'MAE': 5.292177981573996e-05, 'RMSE': 0.0012119240583506156, 'R2': 0.9999984417182236}\n",
      "\n",
      "Training GradientBoostingRegressor...\n",
      "GradientBoostingRegressor Metrics: {'MAE': 0.0027113283440877186, 'RMSE': 0.008856669656250529, 'R2': 0.9999167783982105}\n",
      "\n",
      "Tuning hyperparameters for RandomForestRegressor...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Modeling for rainfall trend analysis in Eastern Nepal.\n",
    "This script splits the feature-engineered data, trains regression and classification models,\n",
    "evaluates performance, tunes hyperparameters, performs cross-validation, and saves the best models.\n",
    "\"\"\"\n",
    "\n",
    "# Define file paths\n",
    "PREPROCESSED_PATH = '../Data/Preprocessed'\n",
    "OUTPUT_PATH = '../Outputs'\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Load feature-engineered data.\"\"\"\n",
    "    try:\n",
    "        data = pd.read_csv(os.path.join(PREPROCESSED_PATH, 'feature_engineered_data.csv'))\n",
    "        data['date'] = pd.to_datetime(data['date'])\n",
    "        print(\"Feature-engineered data loaded successfully.\")\n",
    "        return data\n",
    "    except FileNotFoundError as e:\n",
    "        raise FileNotFoundError(f\"Error: {e}. Check if feature_engineered_data.csv exists in {PREPROCESSED_PATH}\")\n",
    "\n",
    "def split_data(data, target, features):\n",
    "    \"\"\"Split data into training and validation sets without shuffling.\"\"\"\n",
    "    data = data.sort_values('date')  # Ensure chronological order\n",
    "    X = data[features].fillna(0)\n",
    "    y = data[target].fillna(0)\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=0.2, shuffle=False, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"Data split: Training ({len(X_train)} rows), Validation ({len(X_val)} rows)\")\n",
    "    return X_train, X_val, y_train, y_val\n",
    "\n",
    "def evaluate_regression(y_true, y_pred):\n",
    "    \"\"\"Evaluate regression model performance.\"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return {'MAE': mae, 'RMSE': rmse, 'R2': r2}\n",
    "\n",
    "def evaluate_classification(y_true, y_pred, y_pred_proba=None):\n",
    "    \"\"\"Evaluate classification model performance.\"\"\"\n",
    "    metrics = {\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred, zero_division=0),\n",
    "        'Recall': recall_score(y_true, y_pred, zero_division=0),\n",
    "        'F1': f1_score(y_true, y_pred, zero_division=0)\n",
    "    }\n",
    "    if y_pred_proba is not None:\n",
    "        metrics['ROC-AUC'] = roc_auc_score(y_true, y_pred_proba)\n",
    "    return metrics\n",
    "\n",
    "def train_and_evaluate(models, X_train, X_val, y_train, y_val, task='regression'):\n",
    "    \"\"\"Train models and evaluate performance.\"\"\"\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        if task == 'regression':\n",
    "            y_pred = model.predict(X_val)\n",
    "            metrics = evaluate_regression(y_val, y_pred)\n",
    "        else:\n",
    "            y_pred = model.predict(X_val)\n",
    "            y_pred_proba = model.predict_proba(X_val)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "            metrics = evaluate_classification(y_val, y_pred, y_pred_proba)\n",
    "        \n",
    "        results[name] = {'model': model, 'metrics': metrics}\n",
    "        print(f\"{name} Metrics:\", metrics)\n",
    "    return results\n",
    "\n",
    "def hyperparameter_tuning(model, param_grid, X_train, y_train, task='regression'):\n",
    "    \"\"\"Perform hyperparameter tuning with GridSearchCV.\"\"\"\n",
    "    print(f\"\\nTuning hyperparameters for {model.__class__.__name__}...\")\n",
    "    scoring = 'r2' if task == 'regression' else 'f1'\n",
    "    cv = TimeSeriesSplit(n_splits=3)\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best {scoring} score: {grid_search.best_score_:.4f}\")\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "def cross_validation(model, X, y, task='regression'):\n",
    "    \"\"\"Perform time-series cross-validation.\"\"\"\n",
    "    print(f\"\\nCross-validating {model.__class__.__name__}...\")\n",
    "    cv = TimeSeriesSplit(n_splits=5)\n",
    "    scores = []\n",
    "    \n",
    "    for train_idx, val_idx in cv.split(X):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        if task == 'regression':\n",
    "            y_pred = model.predict(X_val)\n",
    "            score = r2_score(y_val, y_pred)\n",
    "        else:\n",
    "            y_pred = model.predict(X_val)\n",
    "            score = f1_score(y_val, y_pred, zero_division=0)\n",
    "        scores.append(score)\n",
    "    \n",
    "    print(f\"Cross-validation scores: {scores}\")\n",
    "    print(f\"Mean CV score: {np.mean(scores):.4f} (±{np.std(scores):.4f})\")\n",
    "    return scores\n",
    "\n",
    "def save_model(model, name):\n",
    "    \"\"\"Save trained model to file.\"\"\"\n",
    "    output_file = os.path.join(OUTPUT_PATH, f'{name}_model.pkl')\n",
    "    with open(output_file, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(f\"Saved {name} model to {output_file}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to execute modeling steps.\"\"\"\n",
    "    # Step: Load and split data\n",
    "    data = load_data()\n",
    "    \n",
    "    # Features (exclude targets and non-numeric columns)\n",
    "    features = [\n",
    "        'ele(meter)', 'lat(deg)', 'lon(deg)', 'year', 'month', 'day_of_year',\n",
    "        'yearly_rainfall', 'monthly_rainfall', 'prev_day_rainfall', 'rolling_mean_7d',\n",
    "        'station_name_x_encoded', 'district_encoded',\n",
    "        'log_rainfall_sum', 'log_yearly_rainfall', 'log_monthly_rainfall',\n",
    "        'log_prev_day_rainfall', 'log_rolling_mean_7d', 'log_day_of_year',\n",
    "        'pca_component_1', 'pca_component_2', 'pca_component_3'\n",
    "    ]\n",
    "    features = [f for f in features if f in data.columns]  # Filter available features\n",
    "    \n",
    "    # Regression task\n",
    "    print(\"\\n--- Regression Task (Predicting rainfall_sum) ---\")\n",
    "    X_train_reg, X_val_reg, y_train_reg, y_val_reg = split_data(data, 'rainfall_sum', features)\n",
    "    \n",
    "    # Choose algorithms (Regression)\n",
    "    regression_models = {\n",
    "        'LinearRegression': LinearRegression(),\n",
    "        'RandomForestRegressor': RandomForestRegressor(random_state=42),\n",
    "        'GradientBoostingRegressor': GradientBoostingRegressor(random_state=42)\n",
    "    }\n",
    "    \n",
    "    # Train and make predictions\n",
    "    reg_results = train_and_evaluate(regression_models, X_train_reg, X_val_reg, y_train_reg, y_val_reg, task='regression')\n",
    "    \n",
    "    # Hyperparameter tuning (Random Forest as example)\n",
    "    rf_reg = RandomForestRegressor(random_state=42)\n",
    "    rf_reg_param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [10, 20, None],\n",
    "        'min_samples_split': [2, 5]\n",
    "    }\n",
    "    best_rf_reg = hyperparameter_tuning(rf_reg, rf_reg_param_grid, X_train_reg, y_train_reg, task='regression')\n",
    "    reg_results['TunedRandomForestRegressor'] = {\n",
    "        'model': best_rf_reg,\n",
    "        'metrics': evaluate_regression(y_val_reg, best_rf_reg.predict(X_val_reg))\n",
    "    }\n",
    "    print(\"Tuned RandomForestRegressor Metrics:\", reg_results['TunedRandomForestRegressor']['metrics'])\n",
    "    \n",
    "    # Cross-validation (Best model)\n",
    "    cv_scores_reg = cross_validation(best_rf_reg, X_train_reg, y_train_reg, task='regression')\n",
    "    \n",
    "    # Classification task\n",
    "    print(\"\\n--- Classification Task (Predicting extreme_rainfall) ---\")\n",
    "    X_train_clf, X_val_clf, y_train_clf, y_val_clf = split_data(data, 'extreme_rainfall', features)\n",
    "    \n",
    "    # Choose algorithms (Classification)\n",
    "    classification_models = {\n",
    "        'LogisticRegression': LogisticRegression(random_state=42),\n",
    "        'RandomForestClassifier': RandomForestClassifier(random_state=42),\n",
    "        'GradientBoostingClassifier': GradientBoostingClassifier(random_state=42)\n",
    "    }\n",
    "    \n",
    "    # Train and make predictions\n",
    "    clf_results = train_and_evaluate(classification_models, X_train_clf, X_val_clf, y_train_clf, y_val_clf, task='classification')\n",
    "    \n",
    "    # Hyperparameter tuning (Random Forest as example)\n",
    "    rf_clf = RandomForestClassifier(random_state=42)\n",
    "    rf_clf_param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [10, 20, None],\n",
    "        'min_samples_split': [2, 5]\n",
    "    }\n",
    "    best_rf_clf = hyperparameter_tuning(rf_clf, rf_clf_param_grid, X_train_clf, y_train_clf, task='classification')\n",
    "    clf_results['TunedRandomForestClassifier'] = {\n",
    "        'model': best_rf_clf,\n",
    "        'metrics': evaluate_classification(y_val_clf, best_rf_clf.predict(X_val_clf), best_rf_clf.predict_proba(X_val_clf)[:, 1])\n",
    "    }\n",
    "    print(\"Tuned RandomForestClassifier Metrics:\", clf_results['TunedRandomForestClassifier']['metrics'])\n",
    "    \n",
    "    # Cross-validation (Best model)\n",
    "    cv_scores_clf = cross_validation(best_rf_clf, X_train_clf, y_train_clf, task='classification')\n",
    "    \n",
    "    # Save evaluation results\n",
    "    with open(os.path.join(OUTPUT_PATH, 'model_evaluation.txt'), 'w') as f:\n",
    "        f.write(\"Regression Results:\\n\")\n",
    "        for name, result in reg_results.items():\n",
    "            f.write(f\"{name}: {result['metrics']}\\n\")\n",
    "        f.write(f\"\\nCross-validation (TunedRandomForestRegressor): {cv_scores_reg}\\n\")\n",
    "        f.write(f\"Mean CV Score: {np.mean(cv_scores_reg):.4f} (±{np.std(cv_scores_reg):.4f})\\n\")\n",
    "        f.write(\"\\nClassification Results:\\n\")\n",
    "        for name, result in clf_results.items():\n",
    "            f.write(f\"{name}: {result['metrics']}\\n\")\n",
    "        f.write(f\"\\nCross-validation (TunedRandomForestClassifier): {cv_scores_clf}\\n\")\n",
    "        f.write(f\"Mean CV Score: {np.mean(cv_scores_clf):.4f} (±{np.std(cv_scores_clf):.4f})\\n\")\n",
    "    \n",
    "    # Save the best models\n",
    "    save_model(best_rf_reg, 'best_random_forest_regressor')\n",
    "    save_model(best_rf_clf, 'best_random_forest_classifier')\n",
    "    \n",
    "    print(\"Modeling completed successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
